{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c17ba98-6741-4855-b4a7-d9affb362cf5",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "0c17ba98-6741-4855-b4a7-d9affb362cf5",
        "outputId": "4b093390-32fa-4945-d776-3fb9b39a6c3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_geometric in /opt/conda/envs/pytorch/lib/python3.10/site-packages (2.7.0)\n",
            "Requirement already satisfied: pandas in /opt/conda/envs/pytorch/lib/python3.10/site-packages (2.3.3)\n",
            "Requirement already satisfied: numpy in /opt/conda/envs/pytorch/lib/python3.10/site-packages (2.1.3)\n",
            "Requirement already satisfied: matplotlib in /opt/conda/envs/pytorch/lib/python3.10/site-packages (3.10.0)\n",
            "Requirement already satisfied: aiohttp in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch_geometric) (3.13.0)\n",
            "Requirement already satisfied: fsspec in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch_geometric) (2025.9.0)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch_geometric) (5.9.3)\n",
            "Requirement already satisfied: pyparsing in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch_geometric) (2.32.5)\n",
            "Requirement already satisfied: tqdm in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->torch_geometric) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch_geometric) (3.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->torch_geometric) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->torch_geometric) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric pandas numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "N2-Pm6gF-jLT"
      },
      "id": "N2-Pm6gF-jLT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afd47f13-e837-45e4-95fe-47b750417567",
      "metadata": {
        "tags": [],
        "id": "afd47f13-e837-45e4-95fe-47b750417567",
        "outputId": "da4822d7-8650-40b3-cf43-15c8779bfb26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added /home/jupyter/GEMS to sys.path\n",
            "Successfully imported custom Dataset class\n"
          ]
        }
      ],
      "source": [
        "# CONSTANTS\n",
        "\n",
        "# Need to download Dataset.py from GEMS directory locally onto vm first\n",
        "# git clone http://github.com/camlab-ethz/GEMS.git\n",
        "# Define root path of cloned GEMS repo\n",
        "GEMS_REPO_ROOT = os.path.expanduser('~/GEMS')\n",
        "\n",
        "# Define the directory path where pre-processed .pt dataset files are located\n",
        "DATA_DIR = os.path.join(os.path.expanduser('~'), 'gcs_pdbbind_mount')\n",
        "\n",
        "# List of dataset files to analyze\n",
        "DATASET_FILES = [\n",
        "    '00AEPL_casf2013.pt',\n",
        "    '00AEPL_casf2013_indep.pt',\n",
        "    '00AEPL_casf2016.pt',\n",
        "    '00AEPL_casf2016_indep.pt',\n",
        "    '00AEPL_train_cleansplit.pt',\n",
        "    '00AEPL_train_pdbbind.pt'\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dynamic Import of Custom Datasets Class\n",
        "# Add the directory to Python's search path.\n",
        "print(f\"Attempting to load custom Dataset class...\")\n",
        "\n",
        "try:\n",
        "  # Add GEMS root to sys.path\n",
        "  if GEMS_REPO_ROOT not in sys.path:\n",
        "    sys.path.append(GEMS_REPO_ROOT)\n",
        "    print(f\"Added {GEMS_REPO_ROOT} to sys.path\")\n",
        "\n",
        "    # Import custom Dataset class from the cloned repo\n",
        "    from Dataset import Dataset as GEMS_Dataset\n",
        "    print(\"Successfully imported custom Dataset class\")\n",
        "\n",
        "    # Import the necessarty PyG components\n",
        "    from torch_geometric.data import Data #, Dataset\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"FATAL ERROR importing GEMS Dataset class: {e}\")\n",
        "    sys.exit(1)  # Exit if classes cannot be imported\n",
        ""
      ],
      "metadata": {
        "id": "o2qZUCseDsx-"
      },
      "id": "o2qZUCseDsx-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84b65371-18d3-4746-a11a-79e605ea1849",
      "metadata": {
        "id": "84b65371-18d3-4746-a11a-79e605ea1849",
        "outputId": "cab64cdf-7597-4130-ae46-afc567a4f99a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame created successfully\n",
            "  PDB_ID  Affinity_pKi_pKd  Num_Atoms  Num_Interactions   Density  \\\n",
            "0   3f3c          0.376250         32               278  8.687500   \n",
            "1   1w3l          0.392500         51               431  8.450980   \n",
            "2   2hb1          0.237500         33               269  8.151515   \n",
            "3   2v00          0.228750         32               252  7.875000   \n",
            "4   1os0          0.376875         60               520  8.666667   \n",
            "\n",
            "   Count_Feature_10  \n",
            "0               6.0  \n",
            "1              18.0  \n",
            "2               5.0  \n",
            "3              12.0  \n",
            "4              18.0  \n"
          ]
        }
      ],
      "source": [
        "def extract_metrics(data_list):\n",
        "   \"\"\"Iterates through list of GEMS datasets and extracts metrics.\"\"\"\n",
        "   metrics = []\n",
        "\n",
        "   num_features = data_list[0].x.size(1)\n",
        "\n",
        "   for i, data in enumerate(data_list):\n",
        "\n",
        "      # Affinity is the y label\n",
        "      affinity = data.y.item()\n",
        "\n",
        "      # ID (Assuming is stored in 'id' attribute)\n",
        "      pdb_id = getattr(data, 'id', f'Complex_{i}')\n",
        "\n",
        "      # Extract Graph Size Metrics\n",
        "      # node features (x): shape is [num_atoms, num_features]\n",
        "      num_nodes = data.x.size(0)\n",
        "\n",
        "      # Edge index: shape is: [2, num_edges]\n",
        "      num_edges = data.edge_index.size(1)\n",
        "\n",
        "      # Atom feature counts\n",
        "      feature_counts_tensor = torch.sum(data.x, dim=0)\n",
        "\n",
        "      # Append the aggregated features to the list\n",
        "      record = {\n",
        "        'PDB_ID': pdb_id,\n",
        "        'Affinity_pKi_pKd': affinity,\n",
        "        'Num_Atoms': num_nodes,\n",
        "        'Num_Interactions': num_edges,\n",
        "        'Density': num_edges / num_nodes,\n",
        "        'Count_Feature_10': num_feat_10\n",
        "      }\n",
        "\n",
        "      # Add feature counts dynamically\n",
        "      for j in range(num_features):\n",
        "        record[f'Feature_{j}'] = feature_counts_tensor[j].item()\n",
        "\n",
        "      metrics.append(record)\n",
        "\n",
        "   return pd.DataFrame(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_data_analysi(df, dataset_name):\n",
        "  \"\"\"Performs data analysis on dataframe and produces visualizations\"\"\"\n",
        "\n",
        "  print(f\"Analyzing {dataset_name} dataset (N={len(df)})...\")\n",
        "\n",
        "  # Affinity Distribution\n",
        "  print(\"\\n[1] Affinity Distribution\")\n",
        "  print(df['Affinity_pKi_pKd'].describe())\n",
        "\n",
        "  plt.figure(figsize=(12, 4))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  df['Affinity_pKi_pKd'].hist(bins=50)\n",
        "  plt.title(f'{dataset_name}: Affinity Distribution')\n",
        "  plt.xlabel('Binding Affinity (pKi/pKd)')\n",
        "  plt.ylabel('Frequency')\n",
        "\n",
        "\n",
        "  # Graph Size Metrics\n",
        "  print(\"\\n[2] Graph Size Metrics\")\n",
        "  print(df[['Num_Atoms', 'Num_Interactions', 'Density']].describe())\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  df[['Num_Atoms', 'Num_Interactions', 'Density']].hist(bins=50)\n",
        "  plt.title(f'{dataset_name}: Graph Size Metrics')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  # Protein Diversity\n",
        "  # Use PDB_ID count to determine protein complexes\n",
        "  unique_complexes = df['PDB_ID'].nunique()\n",
        "  print(f\"\\n[3] Protein Diversity: {unique_proteins} unique proteins\")\n",
        "  print(f\"Redundancy Ratio (Total N / Unique N): {len(df) / unique_complexes:.2f}\")\n",
        "\n",
        "  # Node Feature Frequency\n",
        "  # Summing up total count for the top 5 most frequent features\n",
        "  feature_cols = [col for col in df.columns if col.startswith('Feature_')]\n",
        "  top_5_features = df[feature_cols].sum().nlargest(5).index.tolist()\n",
        "\n",
        "  print(\"\\n[4] Node Feature Frequency\")\n",
        "  print(f\"Top 5 Features: {', '.join(top_5_features)}\")\n",
        "  # TODO: map features to actual atom types\n"
      ],
      "metadata": {
        "id": "PkgO47bZMxxQ"
      },
      "id": "PkgO47bZMxxQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67d6ae0d-592d-48fa-b2f9-87c2786d4407",
      "metadata": {
        "tags": [],
        "id": "67d6ae0d-592d-48fa-b2f9-87c2786d4407",
        "outputId": "833153d3-91a3-4f4b-f555-071490770311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 194 complexes\n",
            "Example data object type: <class 'torch_geometric.data.data.Data'>\n",
            "Number of features: 60\n"
          ]
        }
      ],
      "source": [
        "# Main loop\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    print(f\"FATAL ERROR: Path {DATA_DIR} does not exist.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "for filename in DATASET_FILES:\n",
        "    data_filepath = os.path.join(DATA_DIR, filename)\n",
        "\n",
        "    if not os.path.exists(data_filepath):\n",
        "        print(f\"WARNING: File not found: {data_filepath}. Skipping...\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Loading {filename}...\")\n",
        "    try:\n",
        "        # Load data_list\n",
        "        data_list = torch.load(data_filepath)\n",
        "        print(f\"Example data object type: {type(data_list[0])}\")\n",
        "\n",
        "        # Run analysis\n",
        "        df = extract_metrics(data_list)\n",
        "        run_data_analysis(df, filename)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nFAILED PROCESSING {filename}: {e}\")\n",
        "\n",
        "print(\"--------------| Data analysis completed! |------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b6aab0f-92cf-438a-9a92-e1291e1950fa",
      "metadata": {
        "id": "5b6aab0f-92cf-438a-9a92-e1291e1950fa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "conda-env-pytorch-pytorch",
      "name": "workbench-notebooks.m134",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
    },
    "kernelspec": {
      "display_name": "PyTorch 1-13",
      "language": "python",
      "name": "conda-env-pytorch-pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}