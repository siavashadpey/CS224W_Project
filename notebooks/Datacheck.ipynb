{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17fc51c-439f-4cee-a44c-56c82c268c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GCS data mount is not populated perform following steps in vm:\n",
    "\"\"\"\n",
    "# Stop/Unmount any previous attempts\n",
    "# Try to unmount the directory in case a previous attempt left it mounted\n",
    "# If this fails, it's fine, it just means it wasn't mounted.\n",
    "fusermount -u ~/gcs_pdbbind_mount\n",
    "\n",
    "# If /gcs_pdbbind_mount not visible in file system create dir for local mount point:\n",
    "mkdir ~/gcs_pdbbind_mount\n",
    "\n",
    "# Replace BUCKET_NAME and DIRECTORY_PATH\n",
    "BUCKET_NAME=\"cs224w-2025-mae-gnn-bucket\"\n",
    "DIRECTORY_PATH=\"data/GEMS_pytorch_datasets\"\n",
    "\n",
    "gcsfuse --only-dir \"$DIRECTORY_PATH\" -o allow_other --implicit-dirs \"$BUCKET_NAME\" ~/gcs_pdbbind_mount\n",
    "\n",
    "#Verify the Mount:\n",
    "ls -l ~/gcs_pdbbind_mount\n",
    "\n",
    "# You should see your .pt files listed here, proving the mount worked.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322854a2-4aab-4f1d-b4d8-d9c9043502f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch_geometric pandas matplotlib\n",
    "!pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231452f-761c-4e8e-8b87-ba0e3f66c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Set style for better visualization\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1003c15-5b17-4fc5-8220-606524b3c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"pandas version:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90794e17-16ca-4fb4-9721-6e8dc4f9cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "# Need to download Dataset.py from GEMS directory locally onto vm first\n",
    "# git clone http://github.com/camlab-ethz/GEMS.git\n",
    "# Define root path of cloned GEMS repo\n",
    "GEMS_REPO_ROOT = os.path.expanduser('~/GEMS')\n",
    "\n",
    "# Define the directory path where pre-processed .pt dataset files are located\n",
    "DATA_DIR = os.path.join(os.path.expanduser('~'), 'gcs_pdbbind_mount')\n",
    "\n",
    "# Dataset files to analyze\n",
    "DATASET_FILES_DICT = {\n",
    "    'Train': '00AEPL_train_cleansplit.pt',\n",
    "    'Test': '00AEPL_casf2016.pt'\n",
    "}\n",
    "\n",
    "ALL_ATOMS = ['B', 'C', 'N', 'O', 'P', 'S', 'Se', 'metal', 'halogen']\n",
    "\n",
    "ATOM_HYBRIDIZATION_TYPES = [\"HybridizationType.S\", \"HybridizationType.SP\", \"HybridizationType.SP2\", \"HybridizationType.SP2D\", \"HybridizationType.SP3\", \"HybridizationType.SP3D\", \"HybridizationType.SP3D2\", \"HybridizationType.UNSPECIFIED\"]\n",
    "TOTAL_NUM_H_S = [\"Num_H.0\", \"Num_H.1\", \"Num_H.2\", \"Num_H.3\", \"Num_H.4\"]\n",
    "DEGREES = ['Degree.0', 'Degree.1', 'Degree.2', 'Degree.3', 'Degree.4', 'Degree.5', 'Degree.6', 'Degree.7', 'Degree.8', 'Degree.OTHER']\n",
    "CHIRALITIES = ['Chirality.CHI_UNSPECIFIED', 'Chirality.CHI_TETRAHEDRAL_CW', 'Chirality.CHI_TETRAHEDRAL_CCW', 'Chirality.OTHER']\n",
    "\n",
    "AMINO_ACIDS = [\"ALA\", \"ARG\", \"ASN\", \"ASP\", \"CYS\", \"GLN\", \"GLU\", \"GLY\", \"HIS\", \"ILE\", \"LEU\",\n",
    "            \"LYS\", \"MET\", \"PHE\", \"PRO\", \"SER\", \"THR\", \"TRP\", \"TYR\", \"VAL\"]\n",
    "\n",
    "LIGAND_FEATURE_MAP = ALL_ATOMS + [\"IsInRing\"] + ATOM_HYBRIDIZATION_TYPES + \\\n",
    "                    [\"FORMAL_CHARGE\", \"IS_AROMATIC\", \"MASS/100\", ] + TOTAL_NUM_H_S + \\\n",
    "                    DEGREES + CHIRALITIES\n",
    "FULL_FEATURE_MAP = LIGAND_FEATURE_MAP + AMINO_ACIDS\n",
    "\n",
    "EDGE_FEATURE_MAP = [\"COVALENT_BOND\", \"SELF_LOOP\", \"NON-COVALENT_BOND\", \"EDGE_LENGTH_TO_N/10\", \"EDGE_LENGTH_TO_CA/10\", \"EDGE_LENGTH_TO_C/10\", \"EDGE_LENGTH_TO_CB/10\" ] + \\\n",
    "                   [\"BOND_TYPE_0\", \"BOND_TYPE_1.0\", \"BOND_TYPE_1.5\", \"BOND_TYPE_2.0\", \"BOND_TYPE_3.0\"] + \\\n",
    "                   [\"IS_CONJUGATED\", \"IS_IN_RING\", \"BOND_STEREO.NONE\", \"BOND_STEREO.ANY\", \"BOND_STEREO.E\", \"BOND_STEREO.Z\", \"BOND_STEREO.CIS\", \"BOND_STEREO.TRANS\"]\n",
    "\n",
    "NEW_EDGE_FEATURE_MAP = [\"COVALENT_BOND\", \"SELF_LOOP\", \"NON-COVALENT_BOND\", ] + \\\n",
    "                   [\"BOND_TYPE_0\", \"BOND_TYPE_1.0\", \"BOND_TYPE_1.5\", \"BOND_TYPE_2.0\", \"BOND_TYPE_3.0\"] + \\\n",
    "                   [\"IS_CONJUGATED\", \"IS_IN_RING\", \"BOND_STEREO.NONE\", \"BOND_STEREO.ANY\", \"BOND_STEREO.E\", \"BOND_STEREO.Z\", \"BOND_STEREO.CIS\", \"BOND_STEREO.TRANS\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f630cb45-3c1d-4b7c-9cb4-1e719ffc246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic Import of Custom Datasets Class\n",
    "# Add the directory to Python's search path.\n",
    "print(f\"Attempting to load custom Dataset class...\")\n",
    "\n",
    "try:\n",
    "  # Add GEMS root to sys.path\n",
    "  if GEMS_REPO_ROOT not in sys.path:\n",
    "    sys.path.append(GEMS_REPO_ROOT)\n",
    "    print(f\"Added {GEMS_REPO_ROOT} to sys.path\")\n",
    "\n",
    "    # Import custom Dataset class from the cloned repo\n",
    "    from Dataset import Dataset as GEMS_Dataset\n",
    "    print(\"Successfully imported custom Dataset class\")\n",
    "\n",
    "    # Import the necessarty PyG components\n",
    "    from torch_geometric.data import Data #, Dataset\n",
    "\n",
    "except ImportError as e:\n",
    "    raise RuntimeError(f\"FATAL ERROR importing GEMS Dataset class: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e0801-1361-423f-bea8-199150d5516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_DIR):\n",
    "    raise RuntimeError(f\"FATAL ERROR: Path {DATA_DIR} does not exist.\")\n",
    "\n",
    "#filename = \"B6AE0L_train_cleansplit.pt\"\n",
    "filename = \"00AEPL_casf2016.pt\"\n",
    "example_filename = \"example_dataset_no_dist_edge_feat.pt\"\n",
    "data_filepath = os.path.join(DATA_DIR, filename)\n",
    "if not os.path.exists(data_filepath):\n",
    "    print(f\"WARNING: File not found: {data_filepath}. Skipping...\")\n",
    "    \n",
    "try:\n",
    "    # Load data_list\n",
    "    data_list = torch.load(data_filepath)\n",
    "    example_data_list = torch.load(os.path.join(DATA_DIR, example_filename))\n",
    "    print(f\"data object type: {type(data_list[0])}\")\n",
    "    print(f\"Example data object type: {type(example_data_list[0])}\")\n",
    "except Exception as e:\n",
    "        print(f\"\\nFAILED PROCESSING {filename}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf3c875-562d-4b85-a8a8-5228cd1ead22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary out of each dataset keyed by id:\n",
    "data_dict = dict([(d.id, d) for d in data_list])\n",
    "example_data_dict = dict([(d.id, d) for d in example_data_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6d10e-9c18-424f-8441-c1f90f85b8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_ids = set(data_dict.keys())\n",
    "new_ids = set(example_data_dict.keys())\n",
    "\n",
    "# Find the intersection (the overlapping IDs)\n",
    "overlapping_ids = old_ids.intersection(new_ids)\n",
    "\n",
    "print(f\"Total overlapping IDs found: {len(overlapping_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1e6d84-fed9-44a4-b39b-12d760c15959",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_results = {\n",
    "    'match': 0,\n",
    "    'mismatch': 0,\n",
    "    'mismatch_ids': [],\n",
    "    'mismatch_details': {} # Store details about *which* field mismatched\n",
    "}\n",
    "\n",
    "FIELDS_TO_COMPARE = ['x', 'edge_index', 'edge_attr', 'y', 'n_nodes']\n",
    "\n",
    "for data_id in overlapping_ids:\n",
    "    old_data = data_dict[data_id]\n",
    "    new_data = example_data_dict[data_id]\n",
    "    \n",
    "    mismatch_found = False\n",
    "    mismatched_fields = []\n",
    "\n",
    "    # Iterate through the specific fields you defined\n",
    "    for field in FIELDS_TO_COMPARE:\n",
    "        # 1. Check if the field exists in both objects\n",
    "        if hasattr(old_data, field) and hasattr(new_data, field):\n",
    "            old_tensor = getattr(old_data, field)\n",
    "            new_tensor = getattr(new_data, field)\n",
    "            \n",
    "            # 2. Check for shape consistency\n",
    "            if old_tensor.shape != new_tensor.shape:\n",
    "                mismatch_found = True\n",
    "                mismatched_fields.append(f\"{field} (Shape mismatch: {old_tensor.shape} vs {new_tensor.shape})\")\n",
    "                \n",
    "            # 3. Check for element-wise value equality\n",
    "            # .all() ensures all elements in the comparison tensor are True\n",
    "            elif not (old_tensor == new_tensor).all():\n",
    "                mismatch_found = True\n",
    "                mismatched_fields.append(f\"{field} (Value mismatch)\")\n",
    "                \n",
    "        # Handle cases where a required field is missing in one or both objects\n",
    "        elif field in old_data.keys() or field in new_data.keys():\n",
    "             mismatch_found = True\n",
    "             mismatched_fields.append(f\"{field} (Presence mismatch)\")\n",
    "             \n",
    "    # Tally results based on the loop outcome\n",
    "    if mismatch_found:\n",
    "        match_results['mismatch'] += 1\n",
    "        match_results['mismatch_ids'].append(data_id)\n",
    "        match_results['mismatch_details'][data_id] = mismatched_fields\n",
    "    else:\n",
    "        match_results['match'] += 1\n",
    "\n",
    "print(\"\\n--- Custom Comparison Summary ---\")\n",
    "print(f\"Total matching objects (on specified fields): {match_results['match']}\")\n",
    "print(f\"Total mismatched objects (on specified fields): {match_results['mismatch']}\")\n",
    "\n",
    "if match_results['mismatch'] > 0:\n",
    "    print(\"\\nSample IDs with Detailed Mismatches:\")\n",
    "    for data_id in match_results['mismatch_ids'][:5]:\n",
    "        print(f\"ID {data_id}: Failed on fields: {', '.join(match_results['mismatch_details'][data_id])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2cc8b5-6172-4c8e-80ee-32afe036a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = '1bzc'\n",
    "(data_dict[key], example_data_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5eddd8-2f23-44b7-b1a4-f1d8bf9d1667",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatched_id = match_results['mismatch_ids'][0]\n",
    "\n",
    "old_data = data_dict[mismatched_id]\n",
    "new_data = example_data_dict[mismatched_id]\n",
    "\n",
    "# Example check for the 'pos' tensor (atom coordinates)\n",
    "if not (old_data.pos == new_data.pos).all():\n",
    "    print(f\"ID {mismatched_id}: Mismatch found in the 'pos' tensor.\")\n",
    "    \n",
    "# Example check for the 'x' tensor (node features)\n",
    "if not (old_data.x == new_data.x).all():\n",
    "    print(f\"ID {mismatched_id}: Mismatch found in the 'x' tensor.\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
